{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PoemGeneratorTransformers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EsTvJfaueUi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "QnQngCuweMi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers.tokenization_utils_base import BatchEncoding\n",
        "from transformers import GPT2Config, AutoTokenizer, AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "fUdJOVrgh74j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Data_gen(torch.utils.data.Dataset):\n",
        "    def __init__(self, text_inputs: BatchEncoding, target: BatchEncoding): \n",
        "        self.text_inputs = text_inputs\n",
        "        self.target = target\n",
        "    def __len__(self):\n",
        "        return len(self.target)        \n",
        "    def __getitem__(self, index):\n",
        "        return {'input_num': torch.LongTensor(self.text_inputs[index].ids),'input_attention': torch.LongTensor(self.text_inputs[index].attention_mask),'target_ids': torch.LongTensor(self.labels[index].ids)}\n",
        "\n",
        "\n",
        "def vocab_genarator(text_data, sequence_length):\n",
        "    S = []\n",
        "    W = []\n",
        "    vocab = set()\n",
        "    text_data = text_data.replace('\\n',' ')\n",
        "    splitted_text = text_data.split()\n",
        "    for x in range(0,len(splitted_text) - 2*sequence_length):\n",
        "        sentence = ' '.join(splitted_text[x:x+sequence_length])\n",
        "        word = ' '.join(splitted_text[x+sequence_length: x+2*sequence_length])\n",
        "        S.append(sentence)\n",
        "        W.append(word)\n",
        "        vocab.update(splitted_text[x:x+sequence_length])\n",
        "        x = x+1\n",
        "        vocab.update(word)        \n",
        "    return S, W, vocab\n",
        "\n",
        "def generate_song(model, seed_string):\n",
        "    song = seed_string\n",
        "    current_seed = seed_string\n",
        "    for x in range(20):\n",
        "        song_tokens = lang_tokenizer.encode(current_seed, return_tensors=\"pt\").to(torch.device('cpu'))\n",
        "        song_prediction = model.generate(song_tokens, min_length=10, max_length=30, do_sample=True, repetition_penalty=1.5, temperature=1.5)\n",
        "        song = song+ f'({x}): \\t{lang_tokenizer.decode(song_prediction[0])[len(current_seed):]}\\n'\n",
        "        current_seed = lang_tokenizer.decode(song_prediction[0])[len(current_seed):]\n",
        "\n",
        "if __name__ == '__main__':# This fuction iDistilGPT2 English language model\n",
        "    S, W, vocab = vocab_genarator(open('/content/drive/MyDrive/Assignment3/song.txt').read(), 25)\n",
        "    lang_tokenizer = AutoTokenizer.from_pretrained('distilgpt2')\n",
        "    lang_tokenizer.pad_token = lang_tokenizer.eos_token\n",
        "    S_enc=lang_tokenizer(S, truncation=True, padding=True)\n",
        "    W_enc=lang_tokenizer(W, truncation=True, padding=True)\n",
        "    data_to_loader = Data_gen(S_enc, W_enc)\n",
        "    model = AutoModelForCausalLM.from_pretrained('distilgpt2')\n",
        "    model.to(torch.device('cpu'))\n",
        "    adams_optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    train_data_loader = torch.utils.data.DataLoader(data_to_loader, batch_size=100, shuffle=False)"
      ],
      "metadata": {
        "id": "WbZNWTuqlozN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    for curr_epoch in range(40):\n",
        "    #Train across 40 epochs  \n",
        "        lang_tokens = lang_tokenizer.encode(\"Let the darkness lead us into the light\", return_tensors=\"pt\").to(torch.device('cpu'))\n",
        "        song_prediction = model.generate(lang_tokens, min_length=10, max_length=30, do_sample=True, repetition_penalty=1.5, temperature=1.5)\n",
        "        for i, batch in enumerate(train_data_loader):\n",
        "            adams_optimizer.zero_grad()\n",
        "            outputs = model(batch['input_num'],attention_mask=batch['input_attention'],target=batch['target_ids'])\n",
        "            outputs[0].backward()\n",
        "            adams_optimizer.step()\n",
        "\n",
        "    generate_song(model, \"I love deep learning\")"
      ],
      "metadata": {
        "id": "3FaaqQspekw9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}